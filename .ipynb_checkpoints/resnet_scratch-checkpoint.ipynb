{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatted_time(time_in_seconds):\n",
    "    return(\"time taken for this epoch: \", datetime.fromtimestamp(time_in_seconds).strftime(\"%I:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(data_type, batch_size):\n",
    "    data_path = 'data/'+ data_type + '/'  # data_type = train/test\n",
    "\n",
    "    dataset = torchvision.datasets.ImageFolder(\n",
    "        root = data_path,\n",
    "        transform =  transforms.Compose([transforms.Resize((299,299)), \n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    )\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=1,\n",
    "        pin_memory=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(log_interval, model, device, train_loader, optimizer, epoch, criterion):\n",
    "    model.train() # instructing pytorch that we want to train\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "#         loss = F.nll_loss(output, target)\n",
    "#         loss = F.cross_entropy(output,target)\n",
    "        loss = criterion(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval() # instructing pytorch that we want to evaluate (and not train)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model=torchvision.models.resnet34(pretrained=False, progress=True )\n",
    "# model.to(device)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = data_loader('train', batch_size )\n",
    "test_loader = data_loader('test', batch_size )\n",
    "epochs = 20\n",
    "log_interval=100 # batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(in_features=512, out_features=2)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting at:  2020-01-06 01:51:25\n",
      "Train Epoch: 1 [0/24112 (0%)]\tLoss: 0.788742\n",
      "Train Epoch: 1 [1600/24112 (7%)]\tLoss: 0.691277\n",
      "Train Epoch: 1 [3200/24112 (13%)]\tLoss: 0.560413\n",
      "Train Epoch: 1 [4800/24112 (20%)]\tLoss: 0.705375\n",
      "Train Epoch: 1 [6400/24112 (27%)]\tLoss: 0.663437\n",
      "Train Epoch: 1 [8000/24112 (33%)]\tLoss: 0.681006\n",
      "Train Epoch: 1 [9600/24112 (40%)]\tLoss: 0.737539\n",
      "Train Epoch: 1 [11200/24112 (46%)]\tLoss: 0.689871\n",
      "Train Epoch: 1 [12800/24112 (53%)]\tLoss: 0.486371\n",
      "Train Epoch: 1 [14400/24112 (60%)]\tLoss: 0.717116\n",
      "Train Epoch: 1 [16000/24112 (66%)]\tLoss: 0.721109\n",
      "Train Epoch: 1 [17600/24112 (73%)]\tLoss: 0.691032\n",
      "Train Epoch: 1 [19200/24112 (80%)]\tLoss: 0.949440\n",
      "Train Epoch: 1 [20800/24112 (86%)]\tLoss: 0.679774\n",
      "Train Epoch: 1 [22400/24112 (93%)]\tLoss: 0.611894\n",
      "Train Epoch: 1 [24000/24112 (100%)]\tLoss: 0.705006\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "test() missing 1 required positional argument: 'criterion'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0b6c2133c287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: test() missing 1 required positional argument: 'criterion'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "print('starting at: ',time.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time_epoch = time.time()\n",
    "    \n",
    "    train(log_interval, model, device, train_loader, optimizer, epoch, criterion)\n",
    "    test(model, device, test_loader, criterion)\n",
    "    optimizer.step()\n",
    "    \n",
    "    end_time_epoch = time.time()\n",
    "    total_time_this_epoch = end_time_epoch - start_time_epoch\n",
    "\n",
    "    print('total time taken this epoch: ', formatted_time(total_time_this_epoch))\n",
    "\n",
    "end_time = time.time()\n",
    "print('ending  at: ',time.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print('total time taken: ', round(end_time-start_time,2), ' seconds')\n",
    "total_time_taken = round(end_time-start_time)\n",
    "\n",
    "print('total time taken for training: ', formatted_time(total_time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"catdog_resnetfe34.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "model.eval()\n",
    "\n",
    "transforms =  transforms.Compose([transforms.Resize((299,299)), \n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "def predict(image_path, model):\n",
    "    image = Image.open(image_path)\n",
    "    image_tensor = transforms(image)\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    output = model(image_tensor)\n",
    "    index = output.argmax().item()\n",
    "    if index == 0:\n",
    "        return \"Cat\"\n",
    "    elif index == 1:\n",
    "        return \"Dog\"\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./data/test1/6.jpg\"\n",
    "image = Image.open(image_path)\n",
    "print(predict(image_path, model))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inference = torch.load('catdog_resnet34.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "model_inference.eval()\n",
    "# transforms1 =  transforms.Compose([transforms.Resize((299,299)), \n",
    "#                                          transforms.ToTensor(),\n",
    "#                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "def predict_inference(image_path, model):\n",
    "    image = Image.open(image_path)\n",
    "    image_tensor = transforms(image)\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    output = model_inference(image_tensor)\n",
    "    index = output.argmax().item()\n",
    "    if index == 0:\n",
    "        return \"Cat\"\n",
    "    elif index == 1:\n",
    "        return \"Dog\"\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./data/test1/8.jpg\"\n",
    "image = Image.open(image_path)\n",
    "print(predict_inference(image_path, model))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
